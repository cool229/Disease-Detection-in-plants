{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"##Importing the Requried Modules\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Model\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras import optimizers\nfrom keras.models import Sequential\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D,AveragePooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers.normalization import BatchNormalization\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Use for finding wheather cpu and gpu are present or not.\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##finding where the datasets are present or not (with respect to the kaggle)\n!ls \"../input/plant-treat\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##These are the address of the datasets where training,validatation and testing images is present(if it will be run on different platform then the \n## address must be change as accordingly.\nbase_dir = \"../input/plant-treat/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\"\ntest_dir = \"../input/plant-treat\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device(\"/gpu:0\"):\n    ##Preprocessing images and doing Data Augmentation.\n    train_datagen = ImageDataGenerator(rescale=1./255, ##rescaling the images\n                                       shear_range=0.2, ##Shear_range is requried to give the different shape to the image\n                                       zoom_range=0.2,  ##zoom the images with some factor in given range\n                                       rotation_range = 30, ##rotating images in the range of 0-30 degree\n                                       width_shift_range=0.2, ##Shifting the width of the images\n                                       height_shift_range=0.2, ##Shifting w.r.t height\n                                       fill_mode='nearest') ##Nearest pixel value is chosen\n    \n    ##For Validatation and testing only preprocessing is required is scaling the images in the range of 0-1\n    valid_datagen = ImageDataGenerator(rescale=1./255)\n    test_datagen = ImageDataGenerator(rescale = 1./255)\n\n    ##keeping the batch size to 128 which allow 128 for training at a time and then next 128 images goes for training and so on.\n    batch_size = 128\n    \n\n    ##loading the training images from the respective directory with size as 224*224 and batch size 128 , and shuffling the images so that the model \n    ##becomes robust and it not just remember the datas.\n    training_set = train_datagen.flow_from_directory(base_dir+'/train',\n                                                     target_size=(224, 224),\n                                                     batch_size=batch_size,\n                                                     class_mode='categorical',\n                                                     shuffle=True)\n\n    valid_set = valid_datagen.flow_from_directory(base_dir+'/valid',\n                                                target_size=(224, 224),\n                                                batch_size=batch_size,\n                                                class_mode='categorical')\n    testing_set = test_datagen.flow_from_directory(test_dir +'/test',\n                                                     target_size=(224, 224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Collecting the names of all the 38 classes of the leaf.\nclass_dict = training_set.class_indices\nli = list(class_dict.keys())\ni =0\nlabel_image = {}\nfor j in li:\n    label_image[str(i)]=j\n    i+=1\nprint(label_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(li[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##declaring a variable with images_size of 224\nimage_size = 224","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##total images used in the training purpose and testing purpose\ntrain_num = training_set.samples\nvalid_num = valid_set.samples\nprint(train_num)\nprint(valid_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Creating a Our_own model Res_VGG for training purpose by using both the build methods ResNet and VGG.\n\n# Initializing the CNN\nclassifier = Sequential()\n\n##Convolution Step 1and 2\nclassifier.add(Convolution2D(64, 5, strides = (2, 2), padding = 'valid', input_shape=(224, 224, 3), activation = 'relu'))\nclassifier.add(Convolution2D(128, 5, strides = (1, 1), padding = 'valid', activation = 'relu'))\n#Average Pooling Step1\nclassifier.add(AveragePooling2D(pool_size = (2, 2),strides = (2, 2), padding = 'valid'))\nclassifier.add(BatchNormalization())\n\n##Convolution Step 3 and 4\nclassifier.add(Convolution2D(128, 3, strides = (1, 1), padding='same', activation = 'relu'))\nclassifier.add(Convolution2D(256, 3, strides = (1, 1), padding='same', activation = 'relu'))\n#Max Pooling Step 2\nclassifier.add(MaxPooling2D(pool_size = (2, 2), padding = 'valid'))\nclassifier.add(BatchNormalization())\n\n##Convolution Step 5 and 6\nclassifier.add(Convolution2D(256, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(Convolution2D(384, 3, strides = (1, 1), padding='same', activation = 'relu'))\n#Average Pooling Step 3\nclassifier.add(AveragePooling2D(pool_size = (2, 2), padding='valid'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 7 and 8\nclassifier.add(Convolution2D(512, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(Convolution2D(512, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n#Average Pooling Step 4\nclassifier.add(AveragePooling2D(pool_size = (2, 2), padding='valid'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 9\nclassifier.add(Convolution2D(512, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n#Max Pooling Step 5\nclassifier.add(MaxPooling2D(pool_size = (2, 2), padding='valid'))\nclassifier.add(BatchNormalization())\n\n# Flattening Step\nclassifier.add(Flatten())\n\n# Full Connection Step\nclassifier.add(Dense(units = 4096, activation = 'relu'))\n##adding Dropout of 0.5\nclassifier.add(Dropout(0.5))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = 1000, activation = 'relu'))\n##adding Dropout of 0.3\nclassifier.add(Dropout(0.3))\nclassifier.add(BatchNormalization())\n\n#Taking 38 neuron as output as we have to predict from only 38 classes of the diseases in the plants.\nclassifier.add(Dense(units = 38, activation = 'softmax'))\n#Getting the summary of the model build above.\nclassifier.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Only run this if the pretrained model is not present","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"if(device == 'cuda:0'):\n    with tf.device(\"/gpu:0\"):\n        #Compiling the Model\n        ##Using the Stochastic gradient descent as optimizer with learning rate as 0.005 and decay as 5x10^-5\n        classifier.compile(optimizer=optimizers.SGD(lr=0.005, momentum=0.9, decay=5e-5),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n\n        ##fitting images to Res_VGG \n        historymo = classifier.fit_generator(training_set,\n                            steps_per_epoch=train_num//batch_size,\n                            validation_data=valid_set,\n                            epochs=1,\n                            validation_steps=valid_num//batch_size)\nelse :\n    #Compiling the Model\n        ##Using the Stochastic gradient descent as optimizer with learning rate as 0.005 and decay as 5x10^-5\n        classifier.compile(optimizer=optimizers.SGD(lr=0.005, momentum=0.9, decay=5e-5),\n                      loss='categorical_crossentropy',\n                      metrics=['accuracy'])\n\n        ##fitting images to Res_VGG \n        historymo = classifier.fit_generator(training_set,\n                            steps_per_epoch=train_num//batch_size,\n                            validation_data=valid_set,\n                            epochs=8,\n                            validation_steps=valid_num//batch_size)\n#saving model in .hdf5 \nfilepath=\"Res_VGG_MODEL.hdf5\"\nclassifier.save(filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"###If the pretrained model is present then  execute this also.\n###The trained model can be downloaded from the link given below\n### https://drive.google.com/drive/folders/12BjsyxX7XQ0ExwbxC805S_wZ81mOUJ5M?usp=sharing\n###and then the path is set accordingly as per the the system\ninputmodel = \"../input/testing-model/VGG16Model_new_model_Res_VGG__.hdf5\"\n####loading the model using function of keras\nmodel = tf.keras.models.load_model(inputmodel)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## To be run only if training is done on the system \n#plotting training values\nsns.set()\n\n##Getting training_accuracy datas during the training period for every epochs\nacc = historymo.history['accuracy'] \n##Getting validatation_accuracy during the training period for every epochs\nval_acc = historymo.history['val_accuracy']\n##Training loss for every epochs.\nloss = historymo.history['loss']\n##Validation loss for every epochs\nval_loss = historymo.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n##For saving the plot of accuracy .\nplt.savefig('plotaccRes_VGG.png')\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n##For saving the plot of Loss \nplt.savefig('plotlossRes_VGG.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#For testing the images are available in the given link\n\nhttps://drive.google.com/drive/folders/1pA05-GIGaFphnG1ewFywtUD_JP2b7OLn?usp=sharing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Testing operation\nimage_path = \"../input/plant-treat/test/test/PotatoEarlyBlight5.JPG\"\n##loading image and resizing it as 224*224*3 as the input training image is of size 224*224*3\nnew_img = image.load_img(image_path, target_size=(224, 224))\nimg = image.img_to_array(new_img)\nimg = np.expand_dims(img, axis=0)\n## Normalizing the image\nimg = img/255\n\nprint(\"Following is our prediction:\")\nprediction = model.predict(img)\n# decode the results into a list of tuples (class, description, probability)\n# (one such list for each sample in the batch)\nd = prediction.flatten()\nj = d.max()\n#d = sorted(d, reverse = True)\n#print(sorted(d, reverse = True))\n#print(prediction)\n#print(d)\n#print(j)\nif j>0.75:\n    for index,item in enumerate(d):\n        #Finding the max accuracy and matching in the confidence shown by the model in predicting the class and after that we will find the index to give\n        #it class name\n        if item == j:\n            class_name = li[index]\n            #print(index)\n    plt.figure(figsize = (4,4))\n    plt.imshow(new_img)\n    plt.axis('off')\n    plt.title(class_name)\n    plt.show()\nelse:\n    print(\"Accuracy is below 75%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
